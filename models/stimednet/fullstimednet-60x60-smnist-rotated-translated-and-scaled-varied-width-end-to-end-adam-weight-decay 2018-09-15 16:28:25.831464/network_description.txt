Network created: 2018-09-15 16:36:21.418158
Model: imednet.models.encoder_decoder.FullSTIMEDNet
Data path: ./data/s-mnist/60x60-smnist-rotated-translated-and-scaled-varied-width.mat
Model save path: ./models/stimednet/fullstimednet-60x60-smnist-rotated-translated-and-scaled-varied-width-end-to-end-adam-weight-decay 2018-09-15 16:36:21.418158
Pre-trained IMEDNet model load path: ./models/cnn_encoder_decoder/cfcimednet-40x40-smnist-end-to-end-adam 2018-07-22 17:11:17.144898/
Layer sizes: [60, 20, 35, 54]
Image size: [60, 60, 1]
Optimizer: adam
Learning rate: 0.0005
Momentum: 0.5
 Setting parameters for learning:
   - Samples of data: 20000
   - Epochs: -1
   - Batch size: 128
   - training ratio: 0.7
   - validation ratio: 0.15
   - test ratio: 0.15
     -   validation_interval: 1
     -  test_interval: 1
     -   log_interval: 1
     -   cuda = True
     -  Validation fail: 100
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 0.001
    lr: 0.0005
    weight_decay: 2.5e-05
)
MSELoss()
 saving_epochs = 3
 Learning finished with this parameters:
   - Number of epochs: 3
   - Last train loss: tensor(21.7341, device='cuda:0')
   - Last validation loss: tensor(20.6373, device='cuda:0', grad_fn=<MseLossBackward>)
   Last test loss: tensor(20.5481, device='cuda:0')
   - Elapsed time: 12.468354
   - last validation count: 0
     -   Stop criterion: reset optimizerUser stop
     -  Minimal gradient: tensor(0., device='cuda:0')